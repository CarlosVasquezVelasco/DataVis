{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CarlosVasquezVelasco/DataVis/blob/main/FCF_Script2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install nest_asyncio\n",
        "%pip install yfinance --upgrade --no-cache-dir \n",
        "%pip install pandas\n",
        "%pip install bs4\n",
        "%pip install requests \n",
        "%pip install selenium\n",
        "#%pip install sklearn\n",
        "%pip install streamlit --quiet\n",
        "%pip install pyngrok==4.1.1 --quiet\n",
        "%pip install graphics.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yqx5WmndYFPc",
        "outputId": "ddd5238f-661c-4ed2-b11b-8b974f61f4d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (1.5.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.10/dist-packages (0.2.18)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.5.3)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.22.4)\n",
            "Requirement already satisfied: requests>=2.26 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.27.1)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.9.2)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2022.7.1)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.3.7)\n",
            "Requirement already satisfied: cryptography>=3.3.2 in /usr/local/lib/python3.10/dist-packages (from yfinance) (40.0.2)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.11.2)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.4.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.3.2->yfinance) (1.15.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26->yfinance) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26->yfinance) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26->yfinance) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26->yfinance) (3.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.3.2->yfinance) (2.21)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bs4\n",
            "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4) (2.4.1)\n",
            "Building wheels for collected packages: bs4\n",
            "  Building wheel for bs4 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1257 sha256=e2f79245d0dfa338ce6a17403251ddd024f3dbdf01a3fbe40c75ff92f902029e\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/42/45/b773edc52acb16cd2db4cf1a0b47117e2f69bb4eb300ed0e70\n",
            "Successfully built bs4\n",
            "Installing collected packages: bs4\n",
            "Successfully installed bs4-0.0.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.9.1-py3-none-any.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium) (1.26.15)\n",
            "Collecting trio~=0.17 (from selenium)\n",
            "  Downloading trio-0.22.0-py3-none-any.whl (384 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.9/384.9 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trio-websocket~=0.9 (from selenium)\n",
            "  Downloading trio_websocket-0.10.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2022.12.7)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (23.1.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Collecting async-generator>=1.9 (from trio~=0.17->selenium)\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.4)\n",
            "Collecting outcome (from trio~=0.17->selenium)\n",
            "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.1.1)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting graphics.py\n",
            "  Downloading graphics.py-5.0.1.post1.tar.gz (9.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: graphics.py\n",
            "  Building wheel for graphics.py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for graphics.py: filename=graphics.py-5.0.1.post1-py3-none-any.whl size=10055 sha256=c964c549d90fd0bc00f916ff231c4de09212c41fcb9489d8f5f26b12b1ce0a5a\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/82/52/78626bbacaef8177c7b71d404e4f3ecd9796770ea9cfbf4de5\n",
            "Successfully built graphics.py\n",
            "Installing collected packages: graphics.py\n",
            "Successfully installed graphics.py-5.0.1.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install scikit-learn"
      ],
      "metadata": {
        "id": "r_NjgbKja2Ex",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02656e06-9b59-49d5-c090-76f870ccb759"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "786JqvVa7zKi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "a93b4c88-fad0-4d1c-9ddd-b4da2bc271a2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-c104e6b6f662>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'streamlit'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import re \n",
        "import json\n",
        "import csv \n",
        "import time \n",
        "from bs4 import BeautifulSoup\n",
        "from io import StringIO\n",
        "import requests\n",
        "import os\n",
        "import pandas as pd \n",
        "import nest_asyncio\n",
        "import yfinance as yf\n",
        "from datetime import datetime\n",
        "import lxml\n",
        "from lxml import html\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import streamlit as st"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "zoqpIHfA-FN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile my_app.py"
      ],
      "metadata": {
        "id": "3v1IA6oj0ki2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#headers = {\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:109.0) Gecko/20100101 Firefox/109.0\"}\n",
        "#url = \"https://finance.yahoo.com/quote/ATAI\"\n",
        "#r = requests.get(url)\n",
        "\n",
        "#print(r.status_code)"
      ],
      "metadata": {
        "id": "_7DI4ZxN6Uez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "symbol = 'MELI'\n",
        "\n",
        "url = 'https://finance.yahoo.com/quote/' + symbol + '/balance-sheet?p=' + symbol\n",
        "headers = {\n",
        "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3',\n",
        "    'Accept-Encoding': 'gzip, deflate, br',\n",
        "    'Accept-Language': 'en-US,en;q=0.9',\n",
        "    'Cache-Control': 'max-age=0',\n",
        "    'Connection': 'close',\n",
        "    'DNT': '1', # Do Not Track Request Header \n",
        "    'Pragma': 'no-cache',\n",
        "    'Referrer': 'https://google.com',\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36'\n",
        "}\n",
        "page = requests.get(url, headers = headers)\n",
        "tree = html.fromstring(page.content)\n",
        "tree.xpath(\"//h1/text()\")"
      ],
      "metadata": {
        "id": "xbkODPrxuDJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table_rows = tree.xpath(\"//div[contains(@class, 'D(tbr)')]\")\n",
        "\n",
        "assert len(table_rows) > 0\n",
        "\n",
        "parsed_rows = []\n",
        "\n",
        "for table_row in table_rows:\n",
        "    parsed_row = []\n",
        "    el = table_row.xpath(\"./div\")\n",
        "    \n",
        "    none_count = 0\n",
        "    \n",
        "    for rs in el:\n",
        "        try:\n",
        "            (text,) = rs.xpath('.//span/text()[1]')\n",
        "            parsed_row.append(text)\n",
        "        except ValueError:\n",
        "            parsed_row.append(np.NaN)\n",
        "            none_count += 1\n",
        "\n",
        "    if (none_count < 4):\n",
        "        parsed_rows.append(parsed_row)\n",
        "\n",
        "df = pd.DataFrame(parsed_rows)\n",
        "df"
      ],
      "metadata": {
        "id": "5Dt98mQOExp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(parsed_rows)\n",
        "df = df.set_index(0) # Set the index to the first column: 'Period Ending'.\n",
        "df = df.transpose() # Transpose the DataFrame, so that our header contains the account names\n",
        "\n",
        "# Rename the \"Breakdown\" column to \"Date\"\n",
        "cols = list(df.columns)\n",
        "cols[0] = 'Date'\n",
        "df = df.set_axis(cols, axis='columns', inplace=False)\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "_prIcNGjKvno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "dsEu1HzbKzRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_columns = list(df.columns)[1::] # Take all columns, except the first (which is the 'Date' column)\n",
        "\n",
        "for column_name in numeric_columns:\n",
        "    df[column_name] = df[column_name].str.replace(',', '') # Remove the thousands separator\n",
        "    df[column_name] = df[column_name].astype(np.float64) # Convert the column to float64\n",
        "\n",
        "df.dtypes"
      ],
      "metadata": {
        "id": "GMFgcTvuK7vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FINANCIAL SCRAPING FORMULAS #\n",
        "def get_page(url):\n",
        "    # Set up the request headers that we're going to use, to simulate\n",
        "    # a request by the Chrome browser. Simulating a request from a browser\n",
        "    # is generally good practice when building a scraper\n",
        "    headers = {\n",
        "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3',\n",
        "        'Accept-Encoding': 'gzip, deflate, br',\n",
        "        'Accept-Language': 'en-US,en;q=0.9',\n",
        "        'Cache-Control': 'max-age=0',\n",
        "        'Connection': 'close',\n",
        "        'DNT': '1', # Do Not Track Request Header \n",
        "        'Pragma': 'no-cache',\n",
        "        'Referrer': 'https://google.com',\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36'\n",
        "    }\n",
        "\n",
        "    return requests.get(url, headers=headers)\n",
        "\n",
        "def parse_rows(table_rows):\n",
        "    parsed_rows = []\n",
        "\n",
        "    for table_row in table_rows:\n",
        "        parsed_row = []\n",
        "        el = table_row.xpath(\"./div\")\n",
        "\n",
        "        none_count = 0\n",
        "\n",
        "        for rs in el:\n",
        "            try:\n",
        "                (text,) = rs.xpath('.//span/text()[1]')\n",
        "                parsed_row.append(text)\n",
        "            except ValueError:\n",
        "                parsed_row.append(np.NaN)\n",
        "                none_count += 1\n",
        "\n",
        "        if (none_count < 4):\n",
        "            parsed_rows.append(parsed_row)\n",
        "            \n",
        "    return pd.DataFrame(parsed_rows)\n",
        "\n",
        "def clean_data(df):\n",
        "    df = df.set_index(0) # Set the index to the first column: 'Period Ending'.\n",
        "    df = df.transpose() # Transpose the DataFrame, so that our header contains the account names\n",
        "    \n",
        "    # Rename the \"Breakdown\" column to \"Date\"\n",
        "    cols = list(df.columns)\n",
        "    cols[0] = 'Date'\n",
        "    df = df.set_axis(cols, axis='columns', inplace=False)\n",
        "    \n",
        "    numeric_columns = list(df.columns)[1::] # Take all columns, except the first (which is the 'Date' column)\n",
        "\n",
        "    for column_index in range(1, len(df.columns)): # Take all columns, except the first (which is the 'Date' column)\n",
        "        df.iloc[:,column_index] = df.iloc[:,column_index].str.replace(',', '') # Remove the thousands separator\n",
        "        df.iloc[:,column_index] = df.iloc[:,column_index].astype(np.float64) # Convert the column to float64\n",
        "        \n",
        "    return df\n",
        "\n",
        "def scrape_table(url):\n",
        "    # Fetch the page that we're going to parse\n",
        "    page = get_page(url);\n",
        "\n",
        "    # Parse the page with LXML, so that we can start doing some XPATH queries\n",
        "    # to extract the data that we want\n",
        "    tree = html.fromstring(page.content)\n",
        "\n",
        "    # Fetch all div elements which have class 'D(tbr)'\n",
        "    table_rows = tree.xpath(\"//div[contains(@class, 'D(tbr)')]\")\n",
        "    \n",
        "    # Ensure that some table rows are found; if none are found, then it's possible\n",
        "    # that Yahoo Finance has changed their page layout, or have detected\n",
        "    # that you're scraping the page.\n",
        "    assert len(table_rows) > 0\n",
        "    \n",
        "    df = parse_rows(table_rows)\n",
        "    df = clean_data(df)\n",
        "        \n",
        "    return df"
      ],
      "metadata": {
        "id": "tUtMTXNEK81V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#symbol = \"MELI\"\n",
        "#scrape_table('https://finance.yahoo.com/quote/' + symbol + 'key-statistics?p=' + symbol)"
      ],
      "metadata": {
        "id": "ndhdNfkWS4a3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#symbol = 'MELI'\n",
        "df_balance_sheet = scrape_table('https://finance.yahoo.com/quote/' + symbol + '/balance-sheet?p=' + symbol)\n",
        "df_balance_sheet"
      ],
      "metadata": {
        "id": "opZvY5CI9t_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scrape_table('https://finance.yahoo.com/quote/' + symbol + '/financials?p=' + symbol)"
      ],
      "metadata": {
        "id": "urxssPE4LNZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MELI = yf.Ticker('MELI')\n",
        "# MELI.get_shares_full(start=\"2022-01-01\", end=None)[-1]\n",
        "\n",
        "# Gets the most recent shares outstanding by last trading date \n",
        "yf.Ticker(\"AAPL\").get_shares_full(start=\"2022-01-01\", end=None)[-1]"
      ],
      "metadata": {
        "id": "K8ZZhuzBxwVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_free_cashflow(symbol):\n",
        "    #cf_table = pd.read_html(f'https://finance.yahoo.com/quote/{symbol}/cash-flow?p={symbol}')[0]\n",
        "    cf_table = scrape_table('https://finance.yahoo.com/quote/' + symbol + '/cash-flow?p=' + symbol)\n",
        "    table_FCF = cf_table.iloc[[0, 1, 2, 3, 4],[0 ,-1]]\n",
        "    table_FCF2 =  table_FCF.iloc[1:, 1:]\n",
        "\n",
        "    freeCF = []\n",
        "    # Iterate over each row in the dataframe\n",
        "    for index, row in table_FCF2.iterrows():\n",
        "        # Iterate over each cell in the row and append its value to the list\n",
        "        for value in row.values:\n",
        "            freeCF.append(value)\n",
        "\n",
        "    return freeCF\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "RhuNDK1zxyaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freeCF=get_free_cashflow(\"ORCL\")\n",
        "freeCF[-1]"
      ],
      "metadata": {
        "id": "UwVWo_6ZU3fs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "symbol = \"ORCL\"\n",
        "cf_table = scrape_table('https://finance.yahoo.com/quote/' + symbol + '/cash-flow?p=' + symbol)\n",
        "table_FCF = cf_table.iloc[[0, 1, 2, 3, 4],[0 ,-1]]\n",
        "table_FCF2 =  table_FCF.iloc[1:, 1:]\n",
        "print(table_FCF2)"
      ],
      "metadata": {
        "id": "16yt6wDOT8Qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_fairvalue(symbol):\n",
        "    # Get free cash flow\n",
        "    freeCF = get_free_cashflow(symbol)\n",
        "\n",
        "    # Get outstanding shares\n",
        "    ticker = yf.Ticker(symbol)\n",
        "    outstandingshares = ticker.get_shares_full(start=\"2022-01-01\", end=None)[-1]\n",
        "    \n",
        "\n",
        "    # Assumptions:\n",
        "    required_rate = 0.07\n",
        "    perpetual_rate = 0.02\n",
        "    cfGrowth = 0.03\n",
        "    years = [1, 2, 3, 4]\n",
        "\n",
        "    futureFCF = []\n",
        "    discountfactor = []\n",
        "    discountedFCF = []\n",
        "\n",
        "    # Terminal value calculation using Perpetuity Method \n",
        "    terminalvalue = (freeCF[0] * (1 + perpetual_rate)) / (required_rate - perpetual_rate)\n",
        "\n",
        "    # Discounting For Loop\n",
        "    for year in years:\n",
        "        futureFCF.append(freeCF[-1] * (1 + cfGrowth) ** year)\n",
        "        discountfactor.append((1 + required_rate) ** year)\n",
        "        #discountedFCF.append(futureFCF[-1] / discountfactor[-1])\n",
        "\n",
        "\n",
        "    for i in range(0, len(years)):\n",
        "      discountedFCF.append(futureFCF[i]/discountfactor[i])\n",
        "\n",
        "    discountedterminalvalue = terminalvalue / (1+required_rate)**4\n",
        "    discountedFCF.append(discountedterminalvalue)\n",
        "\n",
        "    todaysvalue = sum(discountedFCF)\n",
        "    # Intrinsic Value Per Share Calculation\n",
        "    fairvalue = todaysvalue*1000 / outstandingshares\n",
        "\n",
        "    return fairvalue\n",
        "\n",
        "    #return futureFCF\n",
        "    \n",
        "    print(\"The fair value is ${}\".format(round(fairvalue,2)))\n",
        "    #print(futureFCF)\n",
        "\n"
      ],
      "metadata": {
        "id": "QPHKgHTI73-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_fairvalue(\"AAPL\")"
      ],
      "metadata": {
        "id": "bM7FCW9_nXuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ticker(name):\n",
        "\n",
        "    ticker = yf.Ticker(name)  \n",
        "    return ticker"
      ],
      "metadata": {
        "id": "ifhGlQAu0nqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######### MAIN BODY ##########\n",
        "st.title('Fair Value Analysis Tool')\n",
        "st.subheader(\"by Carlos Vasquez-Velasco\")\n",
        "\n",
        "# Containers help separate content. \n",
        "# Make sure to assign relevant names to distinguish containers\n",
        "description = st.container()\n",
        "description.write(\"\"\"The objective of this Webapp is to provide informative data and value-based analysis of equities for the retail investor.\"\"\")\n",
        "\n",
        "######### SIDEBAR MENU ########\n",
        "st.sidebar.header(\"Honors By Contract\")\n",
        "\n",
        "######### MAIN BODY ##########\n",
        "ticker_name = st.text_input(\"Enter ticker to analyze\")\n",
        "ticker = get_ticker(ticker_name)\n",
        "\n",
        "if len(ticker_name) >= 1: \n",
        "  projectedPrice = get_fairvalue(ticker_name)\n",
        "  "
      ],
      "metadata": {
        "id": "TIwGvU1W0MzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######## COMPANY SUMMARY ########\n",
        "\n",
        "# detailed summary on Ticker\n",
        "if st.checkbox('Show company summary'):\n",
        "\n",
        "    st.subheader('Company summary on: ' + str(ticker.info['longName']))\n",
        "    st.write(ticker.info['longBusinessSummary']) \n",
        "\n",
        "######## RAW DATA DATAFRAME ########\n",
        "\n",
        "## Make options inside checkbox bubbles a dropdown menu instead of more checkbox objects.\n",
        "\n",
        "# Raw data for Ticker\n",
        "if st.checkbox('Show raw data'):\n",
        "\n",
        "    if len(ticker_name) < 1:\n",
        "        st.warning(\"Please enter a ticker to analyze\")\n",
        "\n",
        "    # fetches the Fair Value of the Stock \n",
        "    if len(ticker_name) >= 1:\n",
        "      company = get_fairvalue(ticker_name)\n",
        "\n",
        "      st.write(company)\n",
        "      \n",
        "      submitted = st.form_submit_button(\"Submit\")\n",
        "      if submitted:\n",
        "        st.success(\"Loading data!\")"
      ],
      "metadata": {
        "id": "ygDjFdFgLmZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FCF VALUATION #\n",
        "\n",
        "if st.checkbox('Conduct a Free Cash Flow Valuation', symbol):\n",
        "  fcf_Valuation = get_fairvalue(symbol)"
      ],
      "metadata": {
        "id": "bdWCLvbZMuqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok authtoken 2POFa91LcItBpbPVBoqM1qT1xDB_Fixjv9P2Rxrmy3DR5R4Q"
      ],
      "metadata": {
        "id": "jU-ODU0dsS-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup streamlit my_app.py &\n",
        "url = ngrok.connect(port = '8501')\n",
        "print(\"This is the URL: \", url)"
      ],
      "metadata": {
        "id": "KixIAdo1-W2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run my_app.py"
      ],
      "metadata": {
        "id": "hfn8HRZm9ETp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install graphics.py"
      ],
      "metadata": {
        "id": "CvseETNK-goh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_company_description(ticker):\n",
        "    url = f\"https://finance.yahoo.com/quote/{ticker}\"\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"}\n",
        "    response = requests.get(url, headers=headers)\n",
        "    if response.status_code == 200:\n",
        "        start = response.text.find('\\\"longBusinessSummary\\\":\\\"') + 24\n",
        "        end = response.text.find('\\\",\\\"city\\\"')\n",
        "        return response.text[start:end]\n",
        "    else:\n",
        "        return \"Error: Unable to retrieve company description\"\n"
      ],
      "metadata": {
        "id": "TFhHFN-ACvfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_companyProfile(ticker):\n",
        "    \"\"\"\n",
        "    Retrieves the company profile of a given ticker symbol from Yahoo Finance.\n",
        "\n",
        "    Parameters:\n",
        "    ticker (str): The ticker symbol of the company.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary containing the company profile information.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        company = yf.Ticker(ticker)\n",
        "        info = company.info\n",
        "        return info\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n"
      ],
      "metadata": {
        "id": "s-Z3mLa6C1oZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def userInterface():\n",
        "  \n",
        "  enterTicker = str(input(\"Enter the ticker symbol: \"))\n",
        "  profile = get_companyProfile(enterTicker)\n",
        "  companyProfile = profile['longBusinessSummary']\n",
        "  analysisResult = get_fairvalue(enterTicker)\n",
        "  print(enterTicker, companyProfile)\n",
        "  print(\"The fair value of\", enterTicker, \" is: \", analysisResult)\n",
        "  \n"
      ],
      "metadata": {
        "id": "BArjU46L1GsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "userInterface()"
      ],
      "metadata": {
        "id": "MXFDT047EQAz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}